%========================
% Document class and theme
%========================
\documentclass[8pt]{beamer}
\usetheme[progressbar=frametitle]{metropolis}
\setbeamersize{text margin left=10mm, text margin right=10mm}
\usepackage{appendixnumberbeamer} % appendix slide numbering
\setbeamertemplate{theorems}[numbered]

%========================
% Core packages
%========================
\usepackage{amsmath, amsfonts, amssymb, amsthm} % math + theorems
\usepackage{booktabs}        % professional tables
\usepackage{hyperref}        % hyperlinks
\usepackage{xcolor}          % colors
\usepackage{xspace}          % spacing for custom commands

%========================
% Algorithms
%========================
\usepackage{algorithm}
\usepackage{algpseudocode}
\newtheorem{proposition}{Proposition}
\usepackage{bbm}

%========================
% Plots and TikZ
%========================
\usepackage{pgfplots}
\usepgfplotslibrary{dateplot}
\usepackage{tikz}
\usetikzlibrary{positioning}

%========================
% Listings (code)
%========================
\usepackage{listings}
\lstset{
    basicstyle=\ttfamily\small,
    breaklines=true,
    numbers=left,
    numberstyle=\tiny
}

% R style
\lstdefinelanguage{R}{
  morekeywords={TRUE,FALSE},
  deletekeywords={data,frame,length,as,character},
  otherkeywords={0,1,2,3,4,5,6,7,8,9},
  keywordstyle=\color{blue},
  commentstyle=\color{DarkGreen},
  stringstyle=\color{DarkGreen},
  basicstyle=\ttfamily\small
}

% Python style
\lstdefinelanguage{PythonCustom}{
  language=Python,
  keywordstyle=\color{blue},
  commentstyle=\color{gray},
  stringstyle=\color{red},
  basicstyle=\ttfamily\small
}

%========================
% Custom commands
%========================
\newcommand{\themename}{\textbf{\textsc{metropolis}}\xspace}

%========================
% Custom footline
%========================
\setbeamertemplate{footline}
{%
  \leavevmode%
  \hbox{%
  \begin{beamercolorbox}[wd=.35\paperwidth,ht=2.5ex,dp=1.5ex,center]{author in head/foot}%
    \usebeamerfont{author in head/foot}\insertshortauthor
  \end{beamercolorbox}%
  \begin{beamercolorbox}[wd=.3\paperwidth,ht=2.5ex,dp=1ex,center]{title in head/foot}%
    \usebeamerfont{title in head/foot}\insertshorttitle
  \end{beamercolorbox}%
  \begin{beamercolorbox}[wd=.3\paperwidth,ht=2.5ex,dp=1ex,right]{date in head/foot}%
    \usebeamerfont{date in head/foot}\insertframenumber{} / \inserttotalframenumber
  \end{beamercolorbox}}%
  \vskip0pt%
}

%========================
% Beamer tweaks
%========================
\setbeamertemplate{navigation symbols}{} % remove default navigation symbols


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% AQUI SE DEFINEN LAS IMAGENES PARA UTILIZAR DESPUES
%\pgfdeclareimage[interpolate=true, height=7cm,width=16cm]{halton-points}{halton-points}
%\pgfdeclareimage[interpolate=true, height=3cm, width =4cm]
%{serie-petroleo-reducido}{serie-petroleo-reducido}
%\pgfdeclareimage[interpolate=true, height=3cm, width =4cm]{rectangle-triangle}{rectangle-triangle}
%\pgfdeclareimage[interpolate=true, height=3cm, width =4cm]{any-angle}{any-angle}
%\pgfdeclareimage[interpolate=true, height=3cm, width =4cm]{Pythagoras}{Pythagoras}


\title{Chapter 5 - Beyond Monte Carlo}
\subtitle{Introduction to the Bootstrap Method.}
\author{Prof. Alex Alvarez, Ali Raisolsadat}
\institute{School of Mathematical and Computational Sciences \\ University of Prince Edward Island}
\date{} % leave empty or add \today
%\title[Stat 4110]{Stat 4110 Statistical Simulation}
%\subtitle{}
%\author[University of Prince Edward Island]{School of Mathematical and Computational Sciences \\ University of Prince Edward Island}

%========================
% Begin document
%========================
\begin{document}

%-------------------
% Title frame
%-------------------
\maketitle

%-------------------
% Slide 1: Introduction to Bootstrap Method
%-------------------
\begin{frame}{Introduction to Bootstrap Method}
In Chapter 3 we studied how to use Monte Carlo methods to solve some statistical problems (bias estimation, standard error estimation, validation of confidence intervals).

\vspace{3mm}

By generating many Monte Carlo samples we can obtain important information about the probability distribution of some estimators that cannot be obtained using analytical methods.

\vspace{3mm}
 
In all of these studied cases we generate the Monte Carlo samples from some statistical model (that is, generating values from specific probability distributions).
 \vspace{3mm}
 
What should we do to solve similar problems in the absence of a  probability model?
\end{frame}

%-------------------
% Slide 2: Introduction to Bootstrap Method
%-------------------
\begin{frame}{Introduction to Bootstrap Method}
In Chapter 5 (specifically in Section 5.2) we will study the use of \textbf{resampling methods} in Statistics.

\vspace{3mm}

The main point of resampling methods is being able to generate random samples in the absence of a probabilistic model. In particular we will study a resampling method called \textbf{Bootstrap}.

\vspace{3mm}
 
The Bootstrap method was introduced by Bradley Efron in 1979. In 2019 Efron was awarded the \textbf{Prize in Statistics} for his initial work on the Bootstrap method.
Since 1980 the terms Bootstrap/Bootstrapping have been mentioned in more than 200,000 scientific documents.
\end{frame}

%-------------------
% Slide 3: Bootstrap Method
%-------------------
\begin{frame}{Bootstrap Method Framework}
\textbf{Sample data}: $X=(X_1, X_2, \ldots, X_n)$ independent, identically distributed with $X_i \sim F$, where $F$ is unknown. Usually we observe a realization $x=(x_1,x_2,\ldots, x_n)$ of $X$.

\vspace{3mm}

\textbf{General Problem}: Estimation of some statistic $\theta=\theta(F)$.

\vspace{3mm}
 
For example, it could be the expected value $\displaystyle{\theta=\int y d F(y)}$ or the median $\theta=F^{-1}(1/2)$.

\vspace{3mm}
 
Lets say that we have some estimator $\widehat{\theta}_n=\widehat{\theta}_n(X)$  of $\theta$. 

\vspace{3mm}
 
\textbf{Specific Problems:} Is $\widehat{\theta}_n$ unbiased?, what is the standard deviation of $\widehat{\theta}_n$?, what is the distribution of $\widehat{\theta}_n$?

\vspace{3mm}
  
All these problems are difficult to solve if we do not have a statistical model to generate random samples of $X$.
\end{frame}

%-------------------
% Slide 4: Bootstrap Method
%-------------------
\begin{frame}[fragile]{Bootstrap Method Rationale}
\textbf{Main Idea}: Generate new random samples by sampling (with replacement) from the sample data $x=(x_1, x_2, \ldots, x_n)$. 

\vspace{2mm}

As we will be sampling from the sample data, the Bootstrap method is part of a larger set of \textbf{resampling methods}.

\vspace{2mm}

\textbf{Example}: Create $N=3$ Bootstrap samples from the sample data $x=(5.2, 3.1, 3.4, 4.7, 2.2)$

\vspace{2mm}

\textbf{R Code}(for the generation of a single Bootstrap sample)
\begin{lstlisting}
SampleData<-c(5.2, 3.1, 3.4, 4.7, 2.2)
sample(SampleData, size=5, replace=TRUE)
\end{lstlisting}

Bootstrap Sample 1: $x_1^*=(3.1, 4.7, 2.2, 4.7, 5.2)$\\
Bootstrap Sample 2: $x_2^*=(2.2, 3.1, 5.2, 2.2, 2.2)$\\
Bootstrap Sample 3: $x_3^*=(2.2, 4.7, 3.4, 2.2, 3.4)$\\
\end{frame}

%-------------------
% Slide 5: Bootstrap Method
%-------------------
\begin{frame}{Bootstrap Method Rationale}
These Bootstrap samples can be used in the solution of many problems. For instance, let us compute   $\widehat{\theta}_n(x_j^*)$ for $j=1,2,...,N$ (that is for each Bootstrap sample). Doing this will allow us to create many replications $\widehat{\theta}_n(x_j^*)$ of estimates of $\theta$.

\vspace{2mm}
  
By looking at the whole set of values  $\widehat{\theta}_n(x_j^*)$ we will have more information to assess the uncertainty in $\widehat{\theta}_n(x)$.

\vspace{2mm}
  
The term ``Bootstrap'' comes from the metaphor of {\it ``pulling yourself up  by your bootstraps"},  roughly meaning to succeed in doing  something with own efforts (without outside help). 
\end{frame}

%-------------------
% Slide 6: Bootstrap Method
%-------------------
\begin{frame}{Theoretical Justification of the Method}
From a more conceptual point of view, in the Bootstrap method the original sample has the same role that populations play in standard statistical analysis.

\vspace{2mm}
   
The empirical cumulative distribution function $F_n$ defined as

\begin{equation*}
F_n(t)=\frac{1}{n}\sum_{i=1}^n 1_{(-\infty,t]}(x_i)
\end{equation*}

converges to the actual unknown c.d.f. distribution $F$ as $n$ approaches infinity. Moreover, the approximation $F_n \approx F$ may be valid even for relatively small values of $n$.
\end{frame}

%-------------------
% Slide 7: Bootstrap Method Example
%-------------------
\begin{frame}[fragile]{Example}
\textbf{Example}: Compare the empirical cumulative distribution function obtained from a sample of 50 standard normally distributed random numbers, and the theoretical cumulative distribution function.

\vspace{3mm}
   
\textbf{R Code}

\begin{lstlisting}
xseq = seq(-3,3,length=100)
x = rnorm(50)
plot(ecdf(x))
lines(xseq,pnorm(xseq))
\end{lstlisting}

Resampling from the observations $x=(x_1,x_2,\ldots,x_n)$ is equivalent as sampling from $F_n$. If $F_n$ and $F$ are close then sampling from $F_n$ is roughly equivalent as sampling from $F$.
\end{frame}

%-------------------
% Slide 8: Bootstrap Method
%-------------------
\begin{frame}{Theoretical Justification of the Method}
Having established that the distributions $F_n$ and $F$ are close, we would hope that 
\begin{equation*}
\theta(F_n) \approx \theta(F)
\end{equation*}
This is not true in general (for all statistics $\theta$) but theoretical results can be obtained on a case by case basis. 

\vspace{2mm}
  
This means that if we want to study $\theta(F)$ we can do so by studying  $\theta(F_n)$ using Bootstrap samples that follow the {\bf known} distribution $F_n$. This part of the analysis is not much different than what we did in Chapter 3.
 
\vspace{2mm}
   
During the next few lectures we will apply these ideas to specific  statistical problems.
\end{frame}
\end{document} 


